# ============================================================================
# Bidirectional Agent Chaining - Environment Configuration
# ============================================================================

# ======================
# Google GenAI API Configuration
# ======================

# Required: Google GenAI API Key (get from https://aistudio.google.com/app/apikey)
GOOGLE_API_KEY=your_google_genai_api_key_here

# Optional: Use Vertex AI instead of Gemini Developer API
USE_VERTEX_AI=false
GOOGLE_CLOUD_PROJECT_ID=your_project_id
GOOGLE_CLOUD_LOCATION=us-central1

# ======================
# LangGraph Configuration
# ======================

# Checkpointer backend for conversation memory
LANGGRAPH_CHECKPOINT_BACKEND=memory  # Options: memory, postgres, redis
LANGGRAPH_CHECKPOINT_URI=  # Required for postgres/redis backends

# ======================
# Agent Configuration
# ======================

# Model selection for different agents
SUPPORT_AGENT_MODEL=gemini-2.0-flash-exp
TECHNICAL_AGENT_MODEL=gemini-2.0-flash-exp
PRODUCT_AGENT_MODEL=gemini-2.0-flash-exp

# Temperature settings for different agents (0.0 to 1.0)
SUPPORT_AGENT_TEMPERATURE=0.7
TECHNICAL_AGENT_TEMPERATURE=0.3
PRODUCT_AGENT_TEMPERATURE=0.5

# Maximum tokens for agent responses
MAX_TOKENS_PER_RESPONSE=2048

# ======================
# Chain Orchestration Settings
# ======================

# Maximum number of agent interactions per request
MAX_CHAIN_HOPS=5

# Timeout for individual agent responses (seconds)
AGENT_RESPONSE_TIMEOUT=30

# Maximum conversation history to maintain
MAX_CONVERSATION_HISTORY=10

# ======================
# FastAPI Server Configuration
# ======================

# Server settings
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
SERVER_RELOAD=true

# CORS settings
CORS_ALLOW_ORIGINS=["http://localhost:3000", "http://localhost:8080"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["GET", "POST", "PUT", "DELETE"]
CORS_ALLOW_HEADERS=["*"]

# ======================
# Logging Configuration
# ======================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Enable detailed agent communication logging
ENABLE_AGENT_COMMUNICATION_LOGS=true

# Enable performance monitoring
ENABLE_PERFORMANCE_MONITORING=true

# ======================
# Development & Testing
# ======================

# Environment mode
ENVIRONMENT=development  # Options: development, staging, production

# Enable debug mode
DEBUG=true

# Mock API responses for testing (when true, uses mock responses)
MOCK_API_RESPONSES=false

# ======================
# Security Settings
# ======================

# API Rate limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=100

# Enable request validation
STRICT_REQUEST_VALIDATION=true

# ======================
# Performance Tuning
# ======================

# Async HTTP client settings
HTTP_CLIENT_TIMEOUT=60
HTTP_CLIENT_MAX_CONNECTIONS=100
HTTP_CLIENT_MAX_KEEPALIVE_CONNECTIONS=20

# Proxy settings (if needed)
# HTTPS_PROXY=http://proxy.company.com:8080
# SSL_CERT_FILE=/path/to/cert.pem

# ======================
# Notes
# ======================
# 1. Copy this file to `.env` and update with your actual values
# 2. Never commit the actual `.env` file to version control
# 3. Ensure GOOGLE_API_KEY is set for the system to work
# 4. For production, use Vertex AI with proper service account credentials 